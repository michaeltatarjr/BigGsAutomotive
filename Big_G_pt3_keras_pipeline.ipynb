{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6103df4f-a0ef-4443-9f91-a26c40167404",
   "metadata": {},
   "source": [
    "### Pt. 3 \n",
    "##### Neural Network pipeline for Big G's automotive\n",
    " * This notebook is specifically for a neural network.  Given the df's size (500k, and 243 columns) you might try to run in google colab..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b047c456-a509-4235-92ba-fb86dda57bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22976c6c-bb58-4fda-b398-9db8a3c05b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, confusion_matrix, \n",
    "    f1_score, fbeta_score, \n",
    "    matthews_corrcoef, brier_score_loss\n",
    ")\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1573847b-4246-4f6d-aa28-a6b205871163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read df in\n",
    "#For some reason columns (7,12,15,16,18,19,20,21,22,23,25,27,28) have mixed types. Same warning as in pt. 2. to see warning, delete low_memory=False\n",
    "big_g_df=pd.read_csv('../data/big_g_pipeline_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348bbdaa-d391-4bca-a794-b2b3fcec04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_g_df=big_g_df.drop(columns=['Unnamed: 0',\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accfa8d2-cc9d-4b57-9ccc-6a5500685712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991d91ab-65a8-4244-a200-ab51e7451097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 507342 entries, 0 to 507341\n",
      "Data columns (total 423 columns):\n",
      " #    Column            Dtype  \n",
      "---   ------            -----  \n",
      " 0    EventTimeStamp_x  object \n",
      " 1    1761_1_x          bool   \n",
      " 2    1761_10_x         bool   \n",
      " 3    1761_11_x         bool   \n",
      " 4    1761_17_x         bool   \n",
      " 5    1761_18_x         bool   \n",
      " 6    1761_19_x         bool   \n",
      " 7    1761_3_x          bool   \n",
      " 8    1761_4_x          bool   \n",
      " 9    1761_9_x          bool   \n",
      " 10   3031_18_x         bool   \n",
      " 11   3031_2_x          bool   \n",
      " 12   3031_3_x          bool   \n",
      " 13   3031_4_x          bool   \n",
      " 14   3031_9_x          bool   \n",
      " 15   3216_10_x         bool   \n",
      " 16   3216_11_x         bool   \n",
      " 17   3216_16_x         bool   \n",
      " 18   3216_2_x          bool   \n",
      " 19   3216_20_x         bool   \n",
      " 20   3216_21_x         bool   \n",
      " 21   3216_3_x          bool   \n",
      " 22   3216_4_x          bool   \n",
      " 23   3216_9_x          bool   \n",
      " 24   3217_2_x          bool   \n",
      " 25   3218_2_x          bool   \n",
      " 26   3222_5_x          bool   \n",
      " 27   3226_10_x         bool   \n",
      " 28   3226_11_x         bool   \n",
      " 29   3226_16_x         bool   \n",
      " 30   3226_2_x          bool   \n",
      " 31   3226_20_x         bool   \n",
      " 32   3226_21_x         bool   \n",
      " 33   3226_4_x          bool   \n",
      " 34   3226_9_x          bool   \n",
      " 35   3227_10_x         bool   \n",
      " 36   3227_21_x         bool   \n",
      " 37   3228_2_x          bool   \n",
      " 38   3242_0_x          bool   \n",
      " 39   3242_15_x         bool   \n",
      " 40   3242_16_x         bool   \n",
      " 41   3242_3_x          bool   \n",
      " 42   3242_4_x          bool   \n",
      " 43   3246_0_x          bool   \n",
      " 44   3246_15_x         bool   \n",
      " 45   3246_16_x         bool   \n",
      " 46   3246_2_x          bool   \n",
      " 47   3246_3_x          bool   \n",
      " 48   3246_4_x          bool   \n",
      " 49   3251_0_x          bool   \n",
      " 50   3251_10_x         bool   \n",
      " 51   3251_15_x         bool   \n",
      " 52   3251_16_x         bool   \n",
      " 53   3251_2_x          bool   \n",
      " 54   3251_3_x          bool   \n",
      " 55   3251_4_x          bool   \n",
      " 56   3360_11_x         bool   \n",
      " 57   3360_12_x         bool   \n",
      " 58   3360_19_x         bool   \n",
      " 59   3360_2_x          bool   \n",
      " 60   3360_9_x          bool   \n",
      " 61   3361_12_x         bool   \n",
      " 62   3361_2_x          bool   \n",
      " 63   3361_3_x          bool   \n",
      " 64   3361_4_x          bool   \n",
      " 65   3361_5_x          bool   \n",
      " 66   3362_31_x         bool   \n",
      " 67   3362_7_x          bool   \n",
      " 68   3363_16_x         bool   \n",
      " 69   3363_3_x          bool   \n",
      " 70   3363_4_x          bool   \n",
      " 71   3363_5_x          bool   \n",
      " 72   3363_7_x          bool   \n",
      " 73   3364_10_x         bool   \n",
      " 74   3364_11_x         bool   \n",
      " 75   3364_18_x         bool   \n",
      " 76   3364_3_x          bool   \n",
      " 77   3364_9_x          bool   \n",
      " 78   3480_17_x         bool   \n",
      " 79   3480_2_x          bool   \n",
      " 80   3480_3_x          bool   \n",
      " 81   3480_4_x          bool   \n",
      " 82   3482_2_x          bool   \n",
      " 83   3482_3_x          bool   \n",
      " 84   3482_7_x          bool   \n",
      " 85   3490_3_x          bool   \n",
      " 86   3490_4_x          bool   \n",
      " 87   3490_7_x          bool   \n",
      " 88   3515_10_x         bool   \n",
      " 89   3521_18_x         bool   \n",
      " 90   3556_18_x         bool   \n",
      " 91   3556_2_x          bool   \n",
      " 92   3556_5_x          bool   \n",
      " 93   3610_2_x          bool   \n",
      " 94   3610_3_x          bool   \n",
      " 95   3610_4_x          bool   \n",
      " 96   3703_31_x         bool   \n",
      " 97   3720_15_x         bool   \n",
      " 98   3936_14_x         bool   \n",
      " 99   3936_15_x         bool   \n",
      " 100  3936_16_x         bool   \n",
      " 101  3936_7_x          bool   \n",
      " 102  4094_18_x         bool   \n",
      " 103  4094_31_x         bool   \n",
      " 104  4096_31_x         bool   \n",
      " 105  4331_16_x         bool   \n",
      " 106  4331_18_x         bool   \n",
      " 107  4334_16_x         bool   \n",
      " 108  4334_18_x         bool   \n",
      " 109  4334_2_x          bool   \n",
      " 110  4334_3_x          bool   \n",
      " 111  4334_4_x          bool   \n",
      " 112  4339_7_x          bool   \n",
      " 113  4340_3_x          bool   \n",
      " 114  4340_4_x          bool   \n",
      " 115  4340_5_x          bool   \n",
      " 116  4342_3_x          bool   \n",
      " 117  4342_4_x          bool   \n",
      " 118  4342_5_x          bool   \n",
      " 119  4344_3_x          bool   \n",
      " 120  4344_4_x          bool   \n",
      " 121  4344_5_x          bool   \n",
      " 122  4346_5_x          bool   \n",
      " 123  4360_0_x          bool   \n",
      " 124  4360_10_x         bool   \n",
      " 125  4360_16_x         bool   \n",
      " 126  4360_3_x          bool   \n",
      " 127  4360_4_x          bool   \n",
      " 128  4363_0_x          bool   \n",
      " 129  4363_10_x         bool   \n",
      " 130  4363_16_x         bool   \n",
      " 131  4363_2_x          bool   \n",
      " 132  4363_3_x          bool   \n",
      " 133  4363_4_x          bool   \n",
      " 134  4364_18_x         bool   \n",
      " 135  4364_31_x         bool   \n",
      " 136  4375_2_x          bool   \n",
      " 137  4375_4_x          bool   \n",
      " 138  4376_3_x          bool   \n",
      " 139  4376_4_x          bool   \n",
      " 140  4376_5_x          bool   \n",
      " 141  4376_7_x          bool   \n",
      " 142  4765_16_x         bool   \n",
      " 143  4765_2_x          bool   \n",
      " 144  4765_3_x          bool   \n",
      " 145  4765_4_x          bool   \n",
      " 146  4766_15_x         bool   \n",
      " 147  4766_3_x          bool   \n",
      " 148  4792_14_x         bool   \n",
      " 149  4794_31_x         bool   \n",
      " 150  4795_31_x         bool   \n",
      " 151  4796_31_x         bool   \n",
      " 152  5024_10_x         bool   \n",
      " 153  5031_10_x         bool   \n",
      " 154  520953_4_x        bool   \n",
      " 155  521032_14_x       bool   \n",
      " 156  5246_0            bool   \n",
      " 157  5246_16_x         bool   \n",
      " 158  5298_17_x         bool   \n",
      " 159  5298_18_x         bool   \n",
      " 160  5319_31_x         bool   \n",
      " 161  5392_31_x         bool   \n",
      " 162  5394_3_x          bool   \n",
      " 163  5394_4_x          bool   \n",
      " 164  5394_5_x          bool   \n",
      " 165  5394_7_x          bool   \n",
      " 166  5397_31_x         bool   \n",
      " 167  5491_3_x          bool   \n",
      " 168  5491_4_x          bool   \n",
      " 169  5491_5_x          bool   \n",
      " 170  5491_7_x          bool   \n",
      " 171  5569_2_x          bool   \n",
      " 172  5742_11_x         bool   \n",
      " 173  5742_12_x         bool   \n",
      " 174  5742_16_x         bool   \n",
      " 175  5742_3_x          bool   \n",
      " 176  5742_4_x          bool   \n",
      " 177  5742_9_x          bool   \n",
      " 178  5743_11_x         bool   \n",
      " 179  5743_12_x         bool   \n",
      " 180  5743_3_x          bool   \n",
      " 181  5743_4_x          bool   \n",
      " 182  5743_9_x          bool   \n",
      " 183  5745_18_x         bool   \n",
      " 184  5745_3_x          bool   \n",
      " 185  5745_4_x          bool   \n",
      " 186  5746_4_x          bool   \n",
      " 187  5835_21_x         bool   \n",
      " 188  5835_3_x          bool   \n",
      " 189  5835_4_x          bool   \n",
      " 190  5835_9_x          bool   \n",
      " 191  5848_12_x         bool   \n",
      " 192  5848_13_x         bool   \n",
      " 193  5848_19_x         bool   \n",
      " 194  5848_4_x          bool   \n",
      " 195  5848_9_x          bool   \n",
      " 196  5851_18_x         bool   \n",
      " 197  5851_2_x          bool   \n",
      " 198  5853_10_x         bool   \n",
      " 199  5862_0_x          bool   \n",
      " 200  5862_16_x         bool   \n",
      " 201  5862_2_x          bool   \n",
      " 202  5862_3_x          bool   \n",
      " 203  5862_4_x          bool   \n",
      " 204  6773_16_x         bool   \n",
      " 205  6780_3_x          bool   \n",
      " 206  6802_31_x         bool   \n",
      " 207  7321_4_x          bool   \n",
      " 208  7323_4_x          bool   \n",
      " 209  7854_2_x          bool   \n",
      " 210  7854_3_x          bool   \n",
      " 211  7854_4_x          bool   \n",
      " 212  1569_31           bool   \n",
      " 213  1761_1_y          float64\n",
      " 214  1761_10_y         float64\n",
      " 215  1761_11_y         float64\n",
      " 216  1761_17_y         float64\n",
      " 217  1761_18_y         float64\n",
      " 218  1761_19_y         float64\n",
      " 219  1761_3_y          float64\n",
      " 220  1761_4_y          float64\n",
      " 221  1761_9_y          float64\n",
      " 222  3031_18_y         float64\n",
      " 223  3031_2_y          float64\n",
      " 224  3031_3_y          float64\n",
      " 225  3031_4_y          float64\n",
      " 226  3031_9_y          float64\n",
      " 227  3216_10_y         float64\n",
      " 228  3216_11_y         float64\n",
      " 229  3216_16_y         float64\n",
      " 230  3216_2_y          float64\n",
      " 231  3216_20_y         float64\n",
      " 232  3216_21_y         float64\n",
      " 233  3216_3_y          float64\n",
      " 234  3216_4_y          float64\n",
      " 235  3216_9_y          float64\n",
      " 236  3217_2_y          float64\n",
      " 237  3218_2_y          float64\n",
      " 238  3222_5_y          float64\n",
      " 239  3226_10_y         float64\n",
      " 240  3226_11_y         float64\n",
      " 241  3226_16_y         float64\n",
      " 242  3226_2_y          float64\n",
      " 243  3226_20_y         float64\n",
      " 244  3226_21_y         float64\n",
      " 245  3226_4_y          float64\n",
      " 246  3226_9_y          float64\n",
      " 247  3227_10_y         float64\n",
      " 248  3227_21_y         float64\n",
      " 249  3228_2_y          float64\n",
      " 250  3242_0_y          float64\n",
      " 251  3242_15_y         float64\n",
      " 252  3242_16_y         float64\n",
      " 253  3242_3_y          float64\n",
      " 254  3242_4_y          float64\n",
      " 255  3246_0_y          float64\n",
      " 256  3246_15_y         float64\n",
      " 257  3246_16_y         float64\n",
      " 258  3246_2_y          float64\n",
      " 259  3246_3_y          float64\n",
      " 260  3246_4_y          float64\n",
      " 261  3251_0_y          float64\n",
      " 262  3251_10_y         float64\n",
      " 263  3251_15_y         float64\n",
      " 264  3251_16_y         float64\n",
      " 265  3251_2_y          float64\n",
      " 266  3251_3_y          float64\n",
      " 267  3251_4_y          float64\n",
      " 268  3360_11_y         float64\n",
      " 269  3360_12_y         float64\n",
      " 270  3360_19_y         float64\n",
      " 271  3360_2_y          float64\n",
      " 272  3360_9_y          float64\n",
      " 273  3361_12_y         float64\n",
      " 274  3361_2_y          float64\n",
      " 275  3361_3_y          float64\n",
      " 276  3361_4_y          float64\n",
      " 277  3361_5_y          float64\n",
      " 278  3362_31_y         float64\n",
      " 279  3362_7_y          float64\n",
      " 280  3363_16_y         float64\n",
      " 281  3363_3_y          float64\n",
      " 282  3363_4_y          float64\n",
      " 283  3363_5_y          float64\n",
      " 284  3363_7_y          float64\n",
      " 285  3364_10_y         float64\n",
      " 286  3364_11_y         float64\n",
      " 287  3364_18_y         float64\n",
      " 288  3364_3_y          float64\n",
      " 289  3364_9_y          float64\n",
      " 290  3480_17_y         float64\n",
      " 291  3480_2_y          float64\n",
      " 292  3480_3_y          float64\n",
      " 293  3480_4_y          float64\n",
      " 294  3482_2_y          float64\n",
      " 295  3482_3_y          float64\n",
      " 296  3482_7_y          float64\n",
      " 297  3490_3_y          float64\n",
      " 298  3490_4_y          float64\n",
      " 299  3490_7_y          float64\n",
      " 300  3515_10_y         float64\n",
      " 301  3521_18_y         float64\n",
      " 302  3556_18_y         float64\n",
      " 303  3556_2_y          float64\n",
      " 304  3556_5_y          float64\n",
      " 305  3610_2_y          float64\n",
      " 306  3610_3_y          float64\n",
      " 307  3610_4_y          float64\n",
      " 308  3703_31_y         float64\n",
      " 309  3720_15_y         float64\n",
      " 310  3936_14_y         float64\n",
      " 311  3936_15_y         float64\n",
      " 312  3936_16_y         float64\n",
      " 313  3936_7_y          float64\n",
      " 314  4094_18_y         float64\n",
      " 315  4094_31_y         float64\n",
      " 316  4096_31_y         float64\n",
      " 317  4331_16_y         float64\n",
      " 318  4331_18_y         float64\n",
      " 319  4334_16_y         float64\n",
      " 320  4334_18_y         float64\n",
      " 321  4334_2_y          float64\n",
      " 322  4334_3_y          float64\n",
      " 323  4334_4_y          float64\n",
      " 324  4339_7_y          float64\n",
      " 325  4340_3_y          float64\n",
      " 326  4340_4_y          float64\n",
      " 327  4340_5_y          float64\n",
      " 328  4342_3_y          float64\n",
      " 329  4342_4_y          float64\n",
      " 330  4342_5_y          float64\n",
      " 331  4344_3_y          float64\n",
      " 332  4344_4_y          float64\n",
      " 333  4344_5_y          float64\n",
      " 334  4346_5_y          float64\n",
      " 335  4360_0_y          float64\n",
      " 336  4360_10_y         float64\n",
      " 337  4360_16_y         float64\n",
      " 338  4360_3_y          float64\n",
      " 339  4360_4_y          float64\n",
      " 340  4363_0_y          float64\n",
      " 341  4363_10_y         float64\n",
      " 342  4363_16_y         float64\n",
      " 343  4363_2_y          float64\n",
      " 344  4363_3_y          float64\n",
      " 345  4363_4_y          float64\n",
      " 346  4364_18_y         float64\n",
      " 347  4364_31_y         float64\n",
      " 348  4375_2_y          float64\n",
      " 349  4375_4_y          float64\n",
      " 350  4376_3_y          float64\n",
      " 351  4376_4_y          float64\n",
      " 352  4376_5_y          float64\n",
      " 353  4376_7_y          float64\n",
      " 354  4765_16_y         float64\n",
      " 355  4765_2_y          float64\n",
      " 356  4765_3_y          float64\n",
      " 357  4765_4_y          float64\n",
      " 358  4766_15_y         float64\n",
      " 359  4766_3_y          float64\n",
      " 360  4792_14_y         float64\n",
      " 361  4794_31_y         float64\n",
      " 362  4795_31_y         float64\n",
      " 363  4796_31_y         float64\n",
      " 364  5024_10_y         float64\n",
      " 365  5031_10_y         float64\n",
      " 366  520953_4_y        float64\n",
      " 367  521032_14_y       float64\n",
      " 368  5246_16_y         float64\n",
      " 369  5298_17_y         float64\n",
      " 370  5298_18_y         float64\n",
      " 371  5319_31_y         float64\n",
      " 372  5392_31_y         float64\n",
      " 373  5394_3_y          float64\n",
      " 374  5394_4_y          float64\n",
      " 375  5394_5_y          float64\n",
      " 376  5394_7_y          float64\n",
      " 377  5397_31_y         float64\n",
      " 378  5491_3_y          float64\n",
      " 379  5491_4_y          float64\n",
      " 380  5491_5_y          float64\n",
      " 381  5491_7_y          float64\n",
      " 382  5569_2_y          float64\n",
      " 383  5742_11_y         float64\n",
      " 384  5742_12_y         float64\n",
      " 385  5742_16_y         float64\n",
      " 386  5742_3_y          float64\n",
      " 387  5742_4_y          float64\n",
      " 388  5742_9_y          float64\n",
      " 389  5743_11_y         float64\n",
      " 390  5743_12_y         float64\n",
      " 391  5743_3_y          float64\n",
      " 392  5743_4_y          float64\n",
      " 393  5743_9_y          float64\n",
      " 394  5745_18_y         float64\n",
      " 395  5745_3_y          float64\n",
      " 396  5745_4_y          float64\n",
      " 397  5746_4_y          float64\n",
      " 398  5835_21_y         float64\n",
      " 399  5835_3_y          float64\n",
      " 400  5835_4_y          float64\n",
      " 401  5835_9_y          float64\n",
      " 402  5848_12_y         float64\n",
      " 403  5848_13_y         float64\n",
      " 404  5848_19_y         float64\n",
      " 405  5848_4_y          float64\n",
      " 406  5848_9_y          float64\n",
      " 407  5851_18_y         float64\n",
      " 408  5851_2_y          float64\n",
      " 409  5853_10_y         float64\n",
      " 410  5862_0_y          float64\n",
      " 411  5862_16_y         float64\n",
      " 412  5862_2_y          float64\n",
      " 413  5862_3_y          float64\n",
      " 414  5862_4_y          float64\n",
      " 415  6773_16_y         float64\n",
      " 416  6780_3_y          float64\n",
      " 417  6802_31_y         float64\n",
      " 418  7321_4_y          float64\n",
      " 419  7323_4_y          float64\n",
      " 420  7854_2_y          float64\n",
      " 421  7854_3_y          float64\n",
      " 422  7854_4_y          float64\n",
      "dtypes: bool(212), float64(210), object(1)\n",
      "memory usage: 919.3+ MB\n"
     ]
    }
   ],
   "source": [
    "big_g_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e76910-065c-48af-bdf0-d7ea627cd39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EventTimeStamp_x', '1761_1_x', '1761_10_x', '1761_11_x', '1761_17_x', '1761_18_x', '1761_19_x', '1761_3_x', '1761_4_x', '1761_9_x', '3031_18_x', '3031_2_x', '3031_3_x', '3031_4_x', '3031_9_x', '3216_10_x', '3216_11_x', '3216_16_x', '3216_2_x', '3216_20_x', '3216_21_x', '3216_3_x', '3216_4_x', '3216_9_x', '3217_2_x', '3218_2_x', '3222_5_x', '3226_10_x', '3226_11_x', '3226_16_x', '3226_2_x', '3226_20_x', '3226_21_x', '3226_4_x', '3226_9_x', '3227_10_x', '3227_21_x', '3228_2_x', '3242_0_x', '3242_15_x', '3242_16_x', '3242_3_x', '3242_4_x', '3246_0_x', '3246_15_x', '3246_16_x', '3246_2_x', '3246_3_x', '3246_4_x', '3251_0_x', '3251_10_x', '3251_15_x', '3251_16_x', '3251_2_x', '3251_3_x', '3251_4_x', '3360_11_x', '3360_12_x', '3360_19_x', '3360_2_x', '3360_9_x', '3361_12_x', '3361_2_x', '3361_3_x', '3361_4_x', '3361_5_x', '3362_31_x', '3362_7_x', '3363_16_x', '3363_3_x', '3363_4_x', '3363_5_x', '3363_7_x', '3364_10_x', '3364_11_x', '3364_18_x', '3364_3_x', '3364_9_x', '3480_17_x', '3480_2_x', '3480_3_x', '3480_4_x', '3482_2_x', '3482_3_x', '3482_7_x', '3490_3_x', '3490_4_x', '3490_7_x', '3515_10_x', '3521_18_x', '3556_18_x', '3556_2_x', '3556_5_x', '3610_2_x', '3610_3_x', '3610_4_x', '3703_31_x', '3720_15_x', '3936_14_x', '3936_15_x', '3936_16_x', '3936_7_x', '4094_18_x', '4094_31_x', '4096_31_x', '4331_16_x', '4331_18_x', '4334_16_x', '4334_18_x', '4334_2_x', '4334_3_x', '4334_4_x', '4339_7_x', '4340_3_x', '4340_4_x', '4340_5_x', '4342_3_x', '4342_4_x', '4342_5_x', '4344_3_x', '4344_4_x', '4344_5_x', '4346_5_x', '4360_0_x', '4360_10_x', '4360_16_x', '4360_3_x', '4360_4_x', '4363_0_x', '4363_10_x', '4363_16_x', '4363_2_x', '4363_3_x', '4363_4_x', '4364_18_x', '4364_31_x', '4375_2_x', '4375_4_x', '4376_3_x', '4376_4_x', '4376_5_x', '4376_7_x', '4765_16_x', '4765_2_x', '4765_3_x', '4765_4_x', '4766_15_x', '4766_3_x', '4792_14_x', '4794_31_x', '4795_31_x', '4796_31_x', '5024_10_x', '5031_10_x', '520953_4_x', '521032_14_x', '5246_0', '5246_16_x', '5298_17_x', '5298_18_x', '5319_31_x', '5392_31_x', '5394_3_x', '5394_4_x', '5394_5_x', '5394_7_x', '5397_31_x', '5491_3_x', '5491_4_x', '5491_5_x', '5491_7_x', '5569_2_x', '5742_11_x', '5742_12_x', '5742_16_x', '5742_3_x', '5742_4_x', '5742_9_x', '5743_11_x', '5743_12_x', '5743_3_x', '5743_4_x', '5743_9_x', '5745_18_x', '5745_3_x', '5745_4_x', '5746_4_x', '5835_21_x', '5835_3_x', '5835_4_x', '5835_9_x', '5848_12_x', '5848_13_x', '5848_19_x', '5848_4_x', '5848_9_x', '5851_18_x', '5851_2_x', '5853_10_x', '5862_0_x', '5862_16_x', '5862_2_x', '5862_3_x', '5862_4_x', '6773_16_x', '6780_3_x', '6802_31_x', '7321_4_x', '7323_4_x', '7854_2_x', '7854_3_x', '7854_4_x', '1569_31', '1761_1_y', '1761_10_y', '1761_11_y', '1761_17_y', '1761_18_y', '1761_19_y', '1761_3_y', '1761_4_y', '1761_9_y', '3031_18_y', '3031_2_y', '3031_3_y', '3031_4_y', '3031_9_y', '3216_10_y', '3216_11_y', '3216_16_y', '3216_2_y', '3216_20_y', '3216_21_y', '3216_3_y', '3216_4_y', '3216_9_y', '3217_2_y', '3218_2_y', '3222_5_y', '3226_10_y', '3226_11_y', '3226_16_y', '3226_2_y', '3226_20_y', '3226_21_y', '3226_4_y', '3226_9_y', '3227_10_y', '3227_21_y', '3228_2_y', '3242_0_y', '3242_15_y', '3242_16_y', '3242_3_y', '3242_4_y', '3246_0_y', '3246_15_y', '3246_16_y', '3246_2_y', '3246_3_y', '3246_4_y', '3251_0_y', '3251_10_y', '3251_15_y', '3251_16_y', '3251_2_y', '3251_3_y', '3251_4_y', '3360_11_y', '3360_12_y', '3360_19_y', '3360_2_y', '3360_9_y', '3361_12_y', '3361_2_y', '3361_3_y', '3361_4_y', '3361_5_y', '3362_31_y', '3362_7_y', '3363_16_y', '3363_3_y', '3363_4_y', '3363_5_y', '3363_7_y', '3364_10_y', '3364_11_y', '3364_18_y', '3364_3_y', '3364_9_y', '3480_17_y', '3480_2_y', '3480_3_y', '3480_4_y', '3482_2_y', '3482_3_y', '3482_7_y', '3490_3_y', '3490_4_y', '3490_7_y', '3515_10_y', '3521_18_y', '3556_18_y', '3556_2_y', '3556_5_y', '3610_2_y', '3610_3_y', '3610_4_y', '3703_31_y', '3720_15_y', '3936_14_y', '3936_15_y', '3936_16_y', '3936_7_y', '4094_18_y', '4094_31_y', '4096_31_y', '4331_16_y', '4331_18_y', '4334_16_y', '4334_18_y', '4334_2_y', '4334_3_y', '4334_4_y', '4339_7_y', '4340_3_y', '4340_4_y', '4340_5_y', '4342_3_y', '4342_4_y', '4342_5_y', '4344_3_y', '4344_4_y', '4344_5_y', '4346_5_y', '4360_0_y', '4360_10_y', '4360_16_y', '4360_3_y', '4360_4_y', '4363_0_y', '4363_10_y', '4363_16_y', '4363_2_y', '4363_3_y', '4363_4_y', '4364_18_y', '4364_31_y', '4375_2_y', '4375_4_y', '4376_3_y', '4376_4_y', '4376_5_y', '4376_7_y', '4765_16_y', '4765_2_y', '4765_3_y', '4765_4_y', '4766_15_y', '4766_3_y', '4792_14_y', '4794_31_y', '4795_31_y', '4796_31_y', '5024_10_y', '5031_10_y', '520953_4_y', '521032_14_y', '5246_16_y', '5298_17_y', '5298_18_y', '5319_31_y', '5392_31_y', '5394_3_y', '5394_4_y', '5394_5_y', '5394_7_y', '5397_31_y', '5491_3_y', '5491_4_y', '5491_5_y', '5491_7_y', '5569_2_y', '5742_11_y', '5742_12_y', '5742_16_y', '5742_3_y', '5742_4_y', '5742_9_y', '5743_11_y', '5743_12_y', '5743_3_y', '5743_4_y', '5743_9_y', '5745_18_y', '5745_3_y', '5745_4_y', '5746_4_y', '5835_21_y', '5835_3_y', '5835_4_y', '5835_9_y', '5848_12_y', '5848_13_y', '5848_19_y', '5848_4_y', '5848_9_y', '5851_18_y', '5851_2_y', '5853_10_y', '5862_0_y', '5862_16_y', '5862_2_y', '5862_3_y', '5862_4_y', '6773_16_y', '6780_3_y', '6802_31_y', '7321_4_y', '7323_4_y', '7854_2_y', '7854_3_y', '7854_4_y']\n"
     ]
    }
   ],
   "source": [
    "print(list(big_g_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99f2b8a-a17b-4e3f-8a5b-15dfe3a71ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['1761_1_x', '1761_10_x', '1761_11_x', '1761_17_x', '1761_18_x', '1761_19_x', '1761_3_x', '1761_4_x', '1761_9_x', \n",
    "            '3031_18_x', '3031_2_x', '3031_3_x', '3031_4_x', '3031_9_x', '3216_10_x', '3216_11_x', '3216_16_x', '3216_2_x', '3216_20_x', \n",
    "            '3216_21_x', '3216_3_x', '3216_4_x', '3216_9_x', '3217_2_x', '3218_2_x', '3222_5_x', '3226_10_x', '3226_11_x', '3226_16_x', \n",
    "            '3226_2_x', '3226_20_x', '3226_21_x', '3226_4_x', '3226_9_x', '3227_10_x', '3227_21_x', '3228_2_x', '3242_0_x', '3242_15_x', \n",
    "            '3242_16_x', '3242_3_x', '3242_4_x', '3246_0_x', '3246_15_x', '3246_16_x', '3246_2_x', '3246_3_x', '3246_4_x', '3251_0_x', \n",
    "            '3251_10_x', '3251_15_x', '3251_16_x', '3251_2_x', '3251_3_x', '3251_4_x', '3360_11_x', '3360_12_x', '3360_19_x', '3360_2_x', \n",
    "            '3360_9_x', '3361_12_x', '3361_2_x', '3361_3_x', '3361_4_x', '3361_5_x', '3362_31_x', '3362_7_x', '3363_16_x', '3363_3_x', \n",
    "            '3363_4_x', '3363_5_x', '3363_7_x', '3364_10_x', '3364_11_x', '3364_18_x', '3364_3_x', '3364_9_x', '3480_17_x', '3480_2_x', \n",
    "            '3480_3_x', '3480_4_x', '3482_2_x', '3482_3_x', '3482_7_x', '3490_3_x', '3490_4_x', '3490_7_x', '3515_10_x', '3521_18_x', \n",
    "            '3556_18_x', '3556_2_x', '3556_5_x', '3610_2_x', '3610_3_x', '3610_4_x', '3703_31_x', '3720_15_x', '3936_14_x', '3936_15_x', \n",
    "            '3936_16_x', '3936_7_x', '4094_18_x', '4094_31_x', '4096_31_x', '4331_16_x', '4331_18_x', '4334_16_x', '4334_18_x', '4334_2_x', \n",
    "            '4334_3_x', '4334_4_x', '4339_7_x', '4340_3_x', '4340_4_x', '4340_5_x', '4342_3_x', '4342_4_x', '4342_5_x', '4344_3_x', '4344_4_x', \n",
    "            '4344_5_x', '4346_5_x', '4360_0_x', '4360_10_x', '4360_16_x', '4360_3_x', '4360_4_x', '4363_0_x', '4363_10_x', '4363_16_x', '4363_2_x', \n",
    "            '4363_3_x', '4363_4_x', '4364_18_x', '4364_31_x', '4375_2_x', '4375_4_x', '4376_3_x', '4376_4_x', '4376_5_x', '4376_7_x', '4765_16_x',\n",
    "            '4765_2_x', '4765_3_x', '4765_4_x', '4766_15_x', '4766_3_x', '4792_14_x', '4794_31_x', '4795_31_x', '4796_31_x', '5024_10_x', '5031_10_x',\n",
    "            '520953_4_x', '521032_14_x', '5246_0', '5246_16_x', '5298_17_x', '5298_18_x', '5319_31_x', '5392_31_x', '5394_3_x', '5394_4_x', '5394_5_x',\n",
    "            '5394_7_x', '5397_31_x', '5491_3_x', '5491_4_x', '5491_5_x', '5491_7_x', '5569_2_x', '5742_11_x', '5742_12_x', '5742_16_x', '5742_3_x',\n",
    "            '5742_4_x', '5742_9_x', '5743_11_x', '5743_12_x', '5743_3_x', '5743_4_x', '5743_9_x', '5745_18_x', '5745_3_x', '5745_4_x', '5746_4_x',\n",
    "            '5835_21_x', '5835_3_x', '5835_4_x', '5835_9_x', '5848_12_x', '5848_13_x', '5848_19_x', '5848_4_x', '5848_9_x', '5851_18_x',\n",
    "            '5851_2_x', '5853_10_x', '5862_0_x', '5862_16_x', '5862_2_x', '5862_3_x', '5862_4_x', '6773_16_x', '6780_3_x', '6802_31_x',\n",
    "            '7321_4_x', '7323_4_x', '7854_2_x', '7854_3_x', '7854_4_x', '1761_1_y', '1761_10_y', '1761_11_y', '1761_17_y',\n",
    "            '1761_18_y', '1761_19_y', '1761_3_y', '1761_4_y', '1761_9_y', '3031_18_y', '3031_2_y', '3031_3_y', '3031_4_y', '3031_9_y', \n",
    "            '3216_10_y', '3216_11_y', '3216_16_y', '3216_2_y', '3216_20_y', '3216_21_y', '3216_3_y', '3216_4_y', '3216_9_y', '3217_2_y', \n",
    "            '3218_2_y', '3222_5_y', '3226_10_y', '3226_11_y', '3226_16_y', '3226_2_y', '3226_20_y', '3226_21_y', '3226_4_y', '3226_9_y',\n",
    "            '3227_10_y', '3227_21_y', '3228_2_y', '3242_0_y', '3242_15_y', '3242_16_y', '3242_3_y', '3242_4_y', '3246_0_y', '3246_15_y', \n",
    "            '3246_16_y', '3246_2_y', '3246_3_y', '3246_4_y', '3251_0_y', '3251_10_y', '3251_15_y', '3251_16_y', '3251_2_y', '3251_3_y', \n",
    "            '3251_4_y', '3360_11_y', '3360_12_y', '3360_19_y', '3360_2_y', '3360_9_y', '3361_12_y', '3361_2_y', '3361_3_y', '3361_4_y', \n",
    "            '3361_5_y', '3362_31_y', '3362_7_y', '3363_16_y', '3363_3_y', '3363_4_y', '3363_5_y', '3363_7_y', '3364_10_y', '3364_11_y', \n",
    "            '3364_18_y', '3364_3_y', '3364_9_y', '3480_17_y', '3480_2_y', '3480_3_y', '3480_4_y', '3482_2_y', '3482_3_y', '3482_7_y', \n",
    "            '3490_3_y', '3490_4_y', '3490_7_y', '3515_10_y', '3521_18_y', '3556_18_y', '3556_2_y', '3556_5_y', '3610_2_y', '3610_3_y', \n",
    "            '3610_4_y', '3703_31_y', '3720_15_y', '3936_14_y', '3936_15_y', '3936_16_y', '3936_7_y', '4094_18_y', '4094_31_y', '4096_31_y', \n",
    "            '4331_16_y', '4331_18_y', '4334_16_y', '4334_18_y', '4334_2_y', '4334_3_y', '4334_4_y', '4339_7_y', '4340_3_y', '4340_4_y', \n",
    "            '4340_5_y', '4342_3_y', '4342_4_y', '4342_5_y', '4344_3_y', '4344_4_y', '4344_5_y', '4346_5_y', '4360_0_y', '4360_10_y', \n",
    "            '4360_16_y', '4360_3_y', '4360_4_y', '4363_0_y', '4363_10_y', '4363_16_y', '4363_2_y', '4363_3_y', '4363_4_y', '4364_18_y', \n",
    "            '4364_31_y', '4375_2_y', '4375_4_y', '4376_3_y', '4376_4_y', '4376_5_y', '4376_7_y', '4765_16_y', '4765_2_y', '4765_3_y', \n",
    "            '4765_4_y', '4766_15_y', '4766_3_y', '4792_14_y', '4794_31_y', '4795_31_y', '4796_31_y', '5024_10_y', '5031_10_y', '520953_4_y', \n",
    "            '521032_14_y', '5298_17_y', '5298_18_y', '5319_31_y', '5392_31_y', '5394_3_y', '5394_4_y', '5394_5_y', '5394_7_y', \n",
    "            '5397_31_y', '5491_3_y', '5491_4_y', '5491_5_y', '5491_7_y', '5569_2_y', '5742_11_y', '5742_12_y', '5742_16_y', '5742_3_y', \n",
    "            '5742_4_y', '5742_9_y', '5743_11_y', '5743_12_y', '5743_3_y', '5743_4_y', '5743_9_y', '5745_18_y', '5745_3_y', '5745_4_y', \n",
    "            '5746_4_y', '5835_21_y', '5835_3_y', '5835_4_y', '5835_9_y', '5848_12_y', '5848_13_y', '5848_19_y', '5848_4_y', '5848_9_y', \n",
    "            '5851_18_y', '5851_2_y', '5853_10_y', '5862_0_y', '5862_16_y', '5862_2_y', '5862_3_y', '5862_4_y', '6773_16_y', '6780_3_y', \n",
    "            '6802_31_y', '7321_4_y', '7323_4_y', '7854_2_y', '7854_3_y', '7854_4_y']\n",
    "\n",
    "X = big_g_df[features]\n",
    "y = big_g_df['5246_0']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder().fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "# Perform a train/test split first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 321, train_size = 0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify = y_train, random_state = 321, train_size = 0.6/0.8)\n",
    "\n",
    "# Then scale the predictors\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2a6a06-8192-4d84-8d86-7b5cc65833e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b415c31-5ed4-4888-95cc-63b1306c6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "#Start with a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Then add Dense layer\n",
    "# See https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(units = 25,\n",
    "                          input_shape = (len(features),),\n",
    "                          activation = 'tanh'\n",
    "                          )\n",
    ")\n",
    "\n",
    "# And end with another Dense layer as the output layer.\n",
    "# It needs one node per target category\n",
    "# may want to use something different than softmax, per ds article...\n",
    "# https://en.wikipedia.org/wiki/Softmax_function\n",
    "model.add(tf.keras.layers.Dense(2, activation = 'softmax', use_bias=True))\n",
    "#model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# Finally, compile the model\n",
    "# We need to use sparse categorical crossentropy since our target is encoded as integers\n",
    "# We can also give one or more metrics we want to track as we train out model.\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a51b564-be63-45c4-b318-3bdf054299e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                10550     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 52        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10602 (41.41 KB)\n",
      "Trainable params: 10602 (41.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2198af-0233-4874-be31-297413d58efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9513/9513 [==============================] - 21s 2ms/step - loss: 0.0243 - accuracy: 0.9940\n",
      "Epoch 2/10\n",
      "9513/9513 [==============================] - 19s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 3/10\n",
      "9513/9513 [==============================] - 15s 2ms/step - loss: 4.7537e-04 - accuracy: 0.9999\n",
      "Epoch 4/10\n",
      "9513/9513 [==============================] - 16s 2ms/step - loss: 2.4807e-04 - accuracy: 0.9999\n",
      "Epoch 5/10\n",
      "9513/9513 [==============================] - 21s 2ms/step - loss: 1.4838e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "9513/9513 [==============================] - 14s 2ms/step - loss: 1.1673e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "9513/9513 [==============================] - 20s 2ms/step - loss: 8.2708e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "9513/9513 [==============================] - 18s 2ms/step - loss: 7.0783e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "9513/9513 [==============================] - 23s 2ms/step - loss: 3.5137e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "9513/9513 [==============================] - 20s 2ms/step - loss: 1.2285e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c842e2ff-4adc-4d1f-9dbe-5fe360768b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2d8bf81-2552-423c-ae11-dc5f55dc9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3171/3171 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 3.1590568e-09],\n",
       "       [1.0000000e+00, 3.1590568e-09],\n",
       "       [1.0000000e+00, 3.1590568e-09],\n",
       "       ...,\n",
       "       [1.0000000e+00, 3.1590568e-09],\n",
       "       [1.0000000e+00, 3.1590568e-09],\n",
       "       [1.0000000e+00, 3.1590568e-09]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91dc8b0b-519c-41a3-86c8-83ed7985600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3171/3171 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96733736-7d84-4eb5-9f25-beb1dd1ea0f6",
   "metadata": {},
   "source": [
    "#### Confusion Matrix review:\n",
    " * Top Left    ==True Positive\n",
    " * Bottom Left ==False Positive\n",
    " * Top Right   ==False Negative\n",
    " * Bottom Right==True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbc3246-ad6f-405e-a042-41e7281f0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101421      0]\n",
      " [     0     48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    101421\n",
      "           1       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00    101469\n",
      "   macro avg       1.00      1.00      1.00    101469\n",
      "weighted avg       1.00      1.00      1.00    101469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1b52ff3-c021-45b1-a06f-e5f775f40992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch');\n",
    "#plt.savefig('ta_da!.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ea9d1-b5b9-4c8c-8582-b45a76b34a3b",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    " * Direction and some of the code comes from the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02665fd-eea0-45f8-b7e8-e19c8ba87a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 507342\n",
      "    Positive: 240 (0.05% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(big_g_df['5246_0'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afebf9a0-349f-45ad-8b3d-77fb65fe7c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.65582852])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71904b05-9626-44b9-bc4f-99fa140e5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_length=len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4d8c870-84a4-49c7-899f-db97a76091b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Need to define features, I guess...\n",
    "features_length = len(features)\n",
    "\n",
    "# Add Dense layer with tanh activation function\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(units=2,\n",
    "                          input_shape=(features_length,),\n",
    "                          activation='tanh',\n",
    "                          bias_initializer=tf.keras.initializers.Constant(-1.5)  # Set the initial bias\n",
    "                          )\n",
    ")\n",
    "\n",
    "#maybe try additional hidden layers\n",
    "bias_initializer=tf.keras.initializers.Constant(-1.5)\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', use_bias=True, bias_initializer=bias_initializer))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', use_bias=True, bias_initializer=bias_initializer))\n",
    "\n",
    "# Custom Bias?\n",
    "model.add(tf.keras.layers.Dense(10, activation='sigmoid', use_bias=True, bias_initializer=bias_initializer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0ccbc14-2735-445b-826e-c9de1ee79854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad41cac4-eecf-4894-8127-c80351660469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 10)                4220      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4550 (17.77 KB)\n",
      "Trainable params: 4550 (17.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5143caf6-26c3-40e5-ba73-fca395d14816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5824, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 10) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file48v2mw6k.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5824, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 10) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b79c207-8b22-49a5-9e46-97ea9f5a2073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3171/3171 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af906ca-51ad-4927-9800-2b553f5da407",
   "metadata": {},
   "source": [
    "It's making some predictions, but now it's all off...\n",
    " * UPDATE: Now its back to not making predictions...What happened? Can't seem to find what happened..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b42b3c4-8525-4233-84c6-617b1881b902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101420      1]\n",
      " [     3     45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    101421\n",
      "           1       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           1.00    101469\n",
      "   macro avg       0.99      0.97      0.98    101469\n",
      "weighted avg       1.00      1.00      1.00    101469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28328625-6fa9-433c-a0ce-a473e207da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state = 321)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "719bb629-56dd-4703-b248-7523cdcf40cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 304260, 1: 304260}\n"
     ]
    }
   ],
   "source": [
    "#Note: It's a numpy array, so you can't use .value_counts\n",
    "unique_values, counts=np.unique(y_resampled, return_counts=True)\n",
    "value_counts=dict(zip(unique_values, counts))\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92f15c2f-5916-4bf0-9a5d-027d2ffd59e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19017/19017 [==============================] - 65s 3ms/step - loss: 0.0069 - accuracy: 0.9982\n",
      "Epoch 2/2\n",
      "19017/19017 [==============================] - 52s 3ms/step - loss: 0.0088 - accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(X_train, y_train, epochs = 10)\n",
    "refit=model.fit(X_resampled, y_resampled, epochs = 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34b98ceb-fdab-4959-9903-09ffa0d5b271",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m refit\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "y_pred = refit.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a08da5e9-6b7b-4481-81bd-db7fc69a3d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101420      1]\n",
      " [     3     45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    101421\n",
      "           1       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           1.00    101469\n",
      "   macro avg       0.99      0.97      0.98    101469\n",
      "weighted avg       1.00      1.00      1.00    101469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56ca4c5c-1422-4522-80cc-5edb3ffc464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10459/10459 [==============================] - 18s 2ms/step - loss: 0.0087 - accuracy: 0.9956\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_score(y_val, lr_oversampled\u001b[38;5;241m.\u001b[39mpredict(X_val))\n\u001b[0;32m      7\u001b[0m ratios \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratio\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39marange(start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m, step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m), \u001b[38;5;241m2\u001b[39m)})\n\u001b[1;32m----> 8\u001b[0m ratios[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ratios[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(test_ratio)\n\u001b[0;32m      9\u001b[0m ratios\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m, in \u001b[0;36mtest_ratio\u001b[1;34m(ratio)\u001b[0m\n\u001b[0;32m      3\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m oversampler\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m      4\u001b[0m lr_oversampled \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f1_score(y_val, lr_oversampled\u001b[38;5;241m.\u001b[39mpredict(X_val))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "def test_ratio(ratio):\n",
    "    oversampler = RandomOverSampler(random_state = 321, sampling_strategy=ratio)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    lr_oversampled = model.fit(X_resampled, y_resampled)\n",
    "    return f1_score(y_val, lr_oversampled.predict(X_val))\n",
    "\n",
    "ratios = pd.DataFrame({'ratio': np.round(np.arange(start = 0.1, stop = 1.0, step = 0.05), 2)})\n",
    "ratios['f1'] = ratios['ratio'].apply(test_ratio)\n",
    "ratios.sort_values('f1', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d924fba-051e-478c-a967-9879111ba86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
